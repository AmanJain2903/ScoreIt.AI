{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b38d0b6d",
   "metadata": {},
   "source": [
    "# RESUME DATASET PROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ab1c67",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "30684c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import import_ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d2d871",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "97d31ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readJsonFile(filePath):\n",
    "    with open(filePath, 'r') as jsonFile:\n",
    "        jsonData = json.load(jsonFile)\n",
    "    return jsonData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "13a3dee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractJsonStructureFromObject(data, indent=0):\n",
    "    def printStructure(obj, indent):\n",
    "        spacing = '  ' * indent\n",
    "        if isinstance(obj, dict):\n",
    "            for key, value in obj.items():\n",
    "                print(f\"{spacing}- {key}: {type(value).__name__}\")\n",
    "                printStructure(value, indent + 1)\n",
    "        elif isinstance(obj, list):\n",
    "            print(f\"{spacing}- list of {len(obj)} items\")\n",
    "            if len(obj) > 0:\n",
    "                printStructure(obj[0], indent + 1)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    print(\"JSON Structure:\")\n",
    "    printStructure(data, indent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae537337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcessDataRecord(jsonDataFile):\n",
    "    keysToRemove = ['meta', 'created_at', 'updated_at', 'inner_id', 'total_annotations', 'cancelled_annotations', 'total_predictions', 'comment_count', 'unresolved_comment_count', 'last_comment_updated_at', 'project', 'updated_by', 'comment_authors', 'file_upload', 'drafts', 'predictions', 'agreement']\n",
    "    annotationKeysToRemove = ['id', 'completed_by', 'reviews', 'was_cancelled', 'ground_truth', 'created_at', 'updated_at', 'draft_created_at', 'lead_time', 'prediction', 'result_count', 'unique_id', 'import_id', 'last_action', 'task', 'project', 'updated_by', 'parent_prediction', 'parent_annotation', 'last_created_by']\n",
    "    resultKeysToRemove = ['id', 'origin', 'to_name', 'from_name']\n",
    "    for key in keysToRemove:\n",
    "        if key in jsonDataFile:\n",
    "            del jsonDataFile[key]\n",
    "    for key in annotationKeysToRemove:\n",
    "        for i in range(len(jsonDataFile['annotations'])):\n",
    "            if key in jsonDataFile['annotations'][i]:\n",
    "                del jsonDataFile['annotations'][i][key]\n",
    "    for key in resultKeysToRemove:\n",
    "        for i in range(len(jsonDataFile['annotations'])):\n",
    "            for j in range(len(jsonDataFile['annotations'][i]['result'])):\n",
    "                if key in jsonDataFile['annotations'][i]['result'][j]:\n",
    "                    del jsonDataFile['annotations'][i]['result'][j][key]\n",
    "    jsonDataFile['text'] = jsonDataFile['data']['text']\n",
    "    del jsonDataFile['data']    \n",
    "    for annotation in jsonDataFile['annotations']:\n",
    "        annotation = annotation['result']\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "8086a966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareDataset(datasetFolderPath):\n",
    "    resumeDataset = []\n",
    "    dataFiles = []\n",
    "    for file in os.listdir(datasetFolderPath):\n",
    "        if file.endswith('.json'):\n",
    "            dataFiles.append(os.path.join(datasetFolderPath, file))\n",
    "    for dataFile in dataFiles:\n",
    "        jsonData = readJsonFile(dataFile)\n",
    "        for record in jsonData:\n",
    "            preProcessDataRecord(record)\n",
    "            resumeDataset.append(record)\n",
    "    return resumeDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ef816dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLabels(resumeDataset):\n",
    "    labels = set()\n",
    "    for record in resumeDataset:\n",
    "        for annotation in record['annotations']:\n",
    "            for result in annotation['result']:\n",
    "                if result['type'] == 'labels':\n",
    "                    for i in range(len(result['value']['labels'])):\n",
    "                        labels.add(result['value']['labels'][i])\n",
    "    return list(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "312416cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelEncoderDecoder(labels):\n",
    "    labelEncoder = {\n",
    "        'UNK' : 0\n",
    "    }\n",
    "    tag = 1\n",
    "    for label in labels:\n",
    "        labelEncoder[label] = tag\n",
    "        tag += 1\n",
    "    labelDecoder = {key: value for value, key in labelEncoder.items()}\n",
    "    return labelEncoder, labelDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "eae41dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeIntervals(intervals):\n",
    "    if not intervals:\n",
    "        return []\n",
    "    intervals.sort(key=lambda x: x[0])\n",
    "    merged = [intervals[0]]\n",
    "    for current in intervals[1:]:\n",
    "        last = merged[-1]\n",
    "        if current[0] <= last[1]:\n",
    "            merged[-1] = (last[0], max(last[1], current[1]))\n",
    "        else:\n",
    "            merged.append(current)\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "6a6878d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAnnotations(record, labelEncoder):\n",
    "    annotations = {}\n",
    "    for label in labelEncoder.keys():\n",
    "        annotations[label] = []\n",
    "\n",
    "    for annotation in record['annotations']:\n",
    "        for result in annotation['result']:\n",
    "            if result['type'] == 'labels':\n",
    "                label = result['value']['labels'][0]\n",
    "                start = result['value']['start']\n",
    "                end = result['value']['end']\n",
    "                annotations[label].append((start, end))\n",
    "    for label in annotations.keys():\n",
    "        annotations[label] = mergeIntervals(annotations[label])\n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "0b05f37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOffsetMapping(text):\n",
    "    words = text.split(\" \")\n",
    "    offset_mapping = []\n",
    "    currentIndex = 0\n",
    "    for word in words:\n",
    "        start = currentIndex\n",
    "        end = currentIndex + len(word)\n",
    "        offset_mapping.append((start, end))\n",
    "        currentIndex = end + 1\n",
    "    return offset_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "0066f5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateAnnotationsWithOffsets(record, annotations):\n",
    "    offset_mapping = getOffsetMapping(record['text'])\n",
    "    updatedAnnotations = {}\n",
    "    for label, intervals in annotations.items():\n",
    "        for interval in intervals:\n",
    "            start, end = interval\n",
    "            found = False\n",
    "            startPosition = 0\n",
    "            endPosition = 0\n",
    "            for i, (offset_start, offset_end) in enumerate(offset_mapping):\n",
    "                if offset_start <= start and offset_end >= start and not found:\n",
    "                    startPosition = i\n",
    "                    found = True\n",
    "                if found and offset_end >= end:\n",
    "                    endPosition = i\n",
    "                    break\n",
    "            if label not in updatedAnnotations:\n",
    "                updatedAnnotations[label] = []\n",
    "            updatedAnnotations[label].append((startPosition, endPosition))\n",
    "    return updatedAnnotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd76d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CURRENT ERROR RATE 18% - IMPROVE THIS\n",
    "def verifyAnnotations(resumeDataset, labelEncoder):\n",
    "    mismatches = 0\n",
    "    total = 0\n",
    "    for record in resumeDataset:\n",
    "        annotations = getAnnotations(record, labelEncoder)\n",
    "        updatedAnnotations = updateAnnotationsWithOffsets(record, annotations)\n",
    "        text = record['text']\n",
    "        splitText = text.split(\" \")\n",
    "        for label in annotations:\n",
    "            for i, interval in enumerate(annotations[label]):\n",
    "                start, end = interval\n",
    "                output1 = text[start:end+1]\n",
    "                start2, end2 = updatedAnnotations[label][i]\n",
    "                output2 = splitText[start2:end2+1]\n",
    "                output2 = \" \".join(output2)\n",
    "                output1 = output1.strip()\n",
    "                output2 = output2.strip()\n",
    "                # print(output1, '-------', output2)\n",
    "                # print('----------------------------------------------------')\n",
    "                if output1 != output2:\n",
    "                    # print(f\"Mismatch found in record: {record['id']}\")\n",
    "                    # print(f\"Original: {output1}\")\n",
    "                    # print(f\"Updated: {output2}\")\n",
    "                    # print('----------------------------------------------------')\n",
    "                    mismatches += 1\n",
    "                total += 1\n",
    "    errorRate = mismatches / total if total > 0 else 0\n",
    "    errorRate *= 100\n",
    "    print(f\"Total Annotations: {total}\")\n",
    "    print(f\"Total Mismatches: {mismatches}\")\n",
    "    print(f\"Error Rate: {errorRate:.2f}%\")\n",
    "    return mismatches, total, errorRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "d973dfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelEncoderDecoderIOB(labels):\n",
    "    labelEncoder = {\n",
    "        'O' : 0\n",
    "    }\n",
    "    tag = 1\n",
    "    for label in labels:\n",
    "        labelEncoder['B-' + label] = tag\n",
    "        tag += 1\n",
    "        labelEncoder['I-' + label] = tag\n",
    "        tag += 1\n",
    "    labelDecoder = {key: value for value, key in labelEncoder.items()}\n",
    "    return labelEncoder, labelDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "cc31ecee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToIOB(tokens, nerLabels):\n",
    "    iobLabels = []\n",
    "    prevLabel = 'UNK'\n",
    "\n",
    "    for i, label in enumerate(nerLabels):\n",
    "        if label == 'UNK':\n",
    "            iobLabels.append('O')\n",
    "            prevLabel = 'UNK'\n",
    "        else:\n",
    "            if prevLabel != label:\n",
    "                iobLabels.append('B-' + label)\n",
    "            else:\n",
    "                iobLabels.append('I-' + label)\n",
    "            prevLabel = label\n",
    "\n",
    "    return iobLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "d8a9399e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOutput(record, labelEncoder):\n",
    "    input = record['input']\n",
    "    annotations = record['annotations']\n",
    "    NER_LABELS = ['UNK' for _ in range(len(input))]\n",
    "    NER_TAGS = []\n",
    "    for annotation in annotations.keys():\n",
    "        label = annotation\n",
    "        for i, interval in enumerate(annotations[label]):\n",
    "            start, end = interval\n",
    "            for j in range(start, end + 1):\n",
    "                NER_LABELS[j] = label\n",
    "    NER_LABELS = convertToIOB(input, NER_LABELS)\n",
    "    for label in NER_LABELS:\n",
    "        NER_TAGS.append(labelEncoder[label])\n",
    "    return NER_LABELS, NER_TAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "bf0797f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildDataset(datasetFolderPath):\n",
    "    resumeDataset = prepareDataset(resumeDatasetPath)\n",
    "    labels = getLabels(resumeDataset)\n",
    "\n",
    "    for record in resumeDataset:\n",
    "        labelEncoder, labelDecoder = labelEncoderDecoder(labels)\n",
    "        annotations = getAnnotations(record, labelEncoder)\n",
    "        updatedAnnotations = updateAnnotationsWithOffsets(record, annotations)\n",
    "        record['annotations'] = updatedAnnotations\n",
    "        record['input'] = record['text'].split(\" \")\n",
    "        labelEncoder, labelDecoder = labelEncoderDecoderIOB(labels)\n",
    "        NER_LABELS, NER_TAGS = getOutput(record, labelEncoder)\n",
    "        record['NER_LABELS'] = NER_LABELS\n",
    "        record['NER_TAGS'] = NER_TAGS\n",
    "\n",
    "    dataset = {\n",
    "        'id' : [],\n",
    "        'text' : [],\n",
    "        'annotations' : [],\n",
    "        'input' : [],\n",
    "        'NER_LABELS' : [],\n",
    "        'NER_TAGS' : [] \n",
    "    }\n",
    "\n",
    "    for record in resumeDataset:\n",
    "        dataset['id'].append(record['id'])\n",
    "        dataset['text'].append(record['text'])\n",
    "        dataset['annotations'].append(record['annotations'])\n",
    "        dataset['input'].append(record['input'])\n",
    "        dataset['NER_LABELS'].append(record['NER_LABELS'])\n",
    "        dataset['NER_TAGS'].append(record['NER_TAGS'])\n",
    "\n",
    "    return dataset, labelEncoder, labelDecoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c00b243",
   "metadata": {},
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "fc960948",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetFolderPath = 'Dataset/'\n",
    "resumeDatasetPath = 'Dataset/DatasetFiles'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "7bfa49e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "resumeDataset, labelEncoder, labelDecoder = buildDataset(resumeDatasetPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "3814981d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id  :  <class 'list'>  :  349\n",
      "text  :  <class 'list'>  :  349\n",
      "annotations  :  <class 'list'>  :  349\n",
      "input  :  <class 'list'>  :  349\n",
      "NER_LABELS  :  <class 'list'>  :  349\n",
      "NER_TAGS  :  <class 'list'>  :  349\n"
     ]
    }
   ],
   "source": [
    "for key in resumeDataset.keys():\n",
    "    print(key, ' : ', type(resumeDataset[key]), ' : ', len(resumeDataset[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "e02c916e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON Structure:\n",
      "- id: list\n",
      "  - list of 349 items\n",
      "- text: list\n",
      "  - list of 349 items\n",
      "- annotations: list\n",
      "  - list of 349 items\n",
      "    - place_higher_education: list\n",
      "      - list of 2 items\n",
      "    - company_name: list\n",
      "      - list of 1 items\n",
      "    - technical_skills: list\n",
      "      - list of 32 items\n",
      "    - initiating_actions: list\n",
      "      - list of 12 items\n",
      "    - basic_education: list\n",
      "      - list of 3 items\n",
      "    - work_cities: list\n",
      "      - list of 2 items\n",
      "    - candidate_city: list\n",
      "      - list of 1 items\n",
      "    - designation: list\n",
      "      - list of 2 items\n",
      "    - work_with_people: list\n",
      "      - list of 3 items\n",
      "    - certification: list\n",
      "      - list of 3 items\n",
      "    - work_year: list\n",
      "      - list of 2 items\n",
      "    - languages_known: list\n",
      "      - list of 1 items\n",
      "    - higher_education: list\n",
      "      - list of 1 items\n",
      "    - place_basic_education: list\n",
      "      - list of 2 items\n",
      "    - applying_expertise: list\n",
      "      - list of 21 items\n",
      "- input: list\n",
      "  - list of 349 items\n",
      "    - list of 550 items\n",
      "- NER_LABELS: list\n",
      "  - list of 349 items\n",
      "    - list of 550 items\n",
      "- NER_TAGS: list\n",
      "  - list of 349 items\n",
      "    - list of 550 items\n"
     ]
    }
   ],
   "source": [
    "extractJsonStructureFromObject(resumeDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "c6bc927b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>annotations</th>\n",
       "      <th>input</th>\n",
       "      <th>NER_LABELS</th>\n",
       "      <th>NER_TAGS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69389221</td>\n",
       "      <td>Kalpesh Panchal Azure Certified Cloud Engineer...</td>\n",
       "      <td>{'place_higher_education': [(457, 458), (465, ...</td>\n",
       "      <td>[Kalpesh, Panchal, Azure, Certified, Cloud, En...</td>\n",
       "      <td>[O, O, O, O, O, O, B-candidate_city, I-candida...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 31, 32, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69389222</td>\n",
       "      <td>Kailash Nikam Thane Maharashtra Email me on In...</td>\n",
       "      <td>{'place_higher_education': [(401, 405)], 'comp...</td>\n",
       "      <td>[Kailash, Nikam, Thane, Maharashtra, Email, me...</td>\n",
       "      <td>[O, O, B-candidate_city, I-candidate_city, O, ...</td>\n",
       "      <td>[0, 0, 31, 32, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69389223</td>\n",
       "      <td>Jose George CLOUD ENGINEER Kochi Kerala Email ...</td>\n",
       "      <td>{'company_name': [(27, 28), (107, 108)], 'tech...</td>\n",
       "      <td>[Jose, George, CLOUD, ENGINEER, Kochi, Kerala,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69389224</td>\n",
       "      <td>Job Seeker AWS Certified Solutions Architect A...</td>\n",
       "      <td>{'place_higher_education': [(100, 102)], 'comp...</td>\n",
       "      <td>[Job, Seeker, AWS, Certified, Solutions, Archi...</td>\n",
       "      <td>[O, O, O, O, O, O, O, B-candidate_city, I-cand...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 31, 32, 32, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69389225</td>\n",
       "      <td>JAY PATEL Ahmedabad Gujarat Email me on Indeed...</td>\n",
       "      <td>{'company_name': [(28, 32), (200, 201), (250, ...</td>\n",
       "      <td>[JAY, PATEL, Ahmedabad, Gujarat, Email, me, on...</td>\n",
       "      <td>[O, O, B-candidate_city, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[0, 0, 31, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text  \\\n",
       "0  69389221  Kalpesh Panchal Azure Certified Cloud Engineer...   \n",
       "1  69389222  Kailash Nikam Thane Maharashtra Email me on In...   \n",
       "2  69389223  Jose George CLOUD ENGINEER Kochi Kerala Email ...   \n",
       "3  69389224  Job Seeker AWS Certified Solutions Architect A...   \n",
       "4  69389225  JAY PATEL Ahmedabad Gujarat Email me on Indeed...   \n",
       "\n",
       "                                         annotations  \\\n",
       "0  {'place_higher_education': [(457, 458), (465, ...   \n",
       "1  {'place_higher_education': [(401, 405)], 'comp...   \n",
       "2  {'company_name': [(27, 28), (107, 108)], 'tech...   \n",
       "3  {'place_higher_education': [(100, 102)], 'comp...   \n",
       "4  {'company_name': [(28, 32), (200, 201), (250, ...   \n",
       "\n",
       "                                               input  \\\n",
       "0  [Kalpesh, Panchal, Azure, Certified, Cloud, En...   \n",
       "1  [Kailash, Nikam, Thane, Maharashtra, Email, me...   \n",
       "2  [Jose, George, CLOUD, ENGINEER, Kochi, Kerala,...   \n",
       "3  [Job, Seeker, AWS, Certified, Solutions, Archi...   \n",
       "4  [JAY, PATEL, Ahmedabad, Gujarat, Email, me, on...   \n",
       "\n",
       "                                          NER_LABELS  \\\n",
       "0  [O, O, O, O, O, O, B-candidate_city, I-candida...   \n",
       "1  [O, O, B-candidate_city, I-candidate_city, O, ...   \n",
       "2  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "3  [O, O, O, O, O, O, O, B-candidate_city, I-cand...   \n",
       "4  [O, O, B-candidate_city, O, O, O, O, O, O, O, ...   \n",
       "\n",
       "                                            NER_TAGS  \n",
       "0  [0, 0, 0, 0, 0, 0, 31, 32, 0, 0, 0, 0, 0, 0, 0...  \n",
       "1  [0, 0, 31, 32, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 31, 32, 32, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 31, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  "
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resumeDataframe = pd.DataFrame(resumeDataset)\n",
    "resumeDataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "b8f295d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "csvDatasetPath = 'Dataset/ResumeDataset.csv'\n",
    "jsonDatasetPath = 'Dataset/ResumeDataset.json'\n",
    "labelEncoderDecoderPath = 'Dataset/LabelEncoderDecoder.json'\n",
    "labelEncoderDecoder = {\n",
    "    'labelEncoder' : labelEncoder,\n",
    "    'labelDecoder' : labelDecoder\n",
    "}\n",
    "resumeDataframe.to_csv(csvDatasetPath, index=False)\n",
    "json.dump(resumeDataset, open(jsonDatasetPath, 'w'), indent=4)\n",
    "json.dump(labelEncoderDecoder, open(labelEncoderDecoderPath, 'w'), indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edb258a",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "4be115dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "record = resumeDataframe.iloc[0]\n",
    "record = resumeDataframe.iloc[0].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "b1998585",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {}\n",
    "for label in record['annotations'].keys():\n",
    "    if label not in output:\n",
    "        output[label] = \"\"\n",
    "    for interval in record['annotations'][label]:\n",
    "        start, end = interval\n",
    "        for i in range(start, end + 1):\n",
    "            output[label] += record['input'][i] + \" \"\n",
    "        output[label] = output[label].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "476a4d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "place_higher_education  :  Mumbai UniversityMumbai Maharashtra\n",
      "----------------------------------------------------\n",
      "company_name  :  Cloudxchangeio\n",
      "----------------------------------------------------\n",
      "technical_skills  :  LB Application gateway traffic managerFront Door VNETsubnetUDR ExpressRoute BastionsCDN Virtual network gatewayPublic IP addressesNetwork security groupsAzure Site recoveryStorage accountsApp ServicesWeb appAPI Management servicesAzure Kubernetes servicesAzure Container RegistryServicenowBMC remedyFreshServiceAzure  Configuring backupAzure MigrateCloudBerryZscalerBarracudaMimecastCloudallySymantec endpoint ProtectionSentinel oneCisco MerakiSolarwinds RMMPrinterlogicExchangeOffice 365AzureActive DirectoryNetworking\n",
      "----------------------------------------------------\n",
      "initiating_actions  :  Implemented multiple network componentsDeployed Azure IaaS virtual machinesCloud services PaaS role instancesBuilding up the strategyImplemented Azure VDIManaging Azure Active DirectoryResponsibleResponsibleMonitoring and configuring AlertsManaging IT support tickets changesResponsibleDeploy Configure Maintain Compute Storage Virtual Network\n",
      "----------------------------------------------------\n",
      "basic_education  :  Bachelor of Computer ScienceHigher Secondary Board 2012SSC Secondary Board\n",
      "----------------------------------------------------\n",
      "work_cities  :  Vashi Navi MumbaiMumbai Maharashtra September\n",
      "----------------------------------------------------\n",
      "candidate_city  :  Mumbai Maharashtra\n",
      "----------------------------------------------------\n",
      "designation  :  Experience Azure Cloud EngineerCloud Infrastructure Engineer SL\n",
      "----------------------------------------------------\n",
      "work_with_people  :  Involved in planning preparing and presentingInvolved in preparing and presentingengaging with Internal Teams Vendors\n",
      "----------------------------------------------------\n",
      "certification  :  Azure Administrator AssociateAzure Network Engineer AssociateAzure Security Engineer Associate\n",
      "----------------------------------------------------\n",
      "work_year  :  July 2020 to PresentSeptember 2019 to July 2020\n",
      "----------------------------------------------------\n",
      "languages_known  :  English\n",
      "----------------------------------------------------\n",
      "higher_education  :  Masters in Computer Science\n",
      "----------------------------------------------------\n",
      "place_basic_education  :  SK Somaiya College of Arts  Mumbai MaharashtraMaharashtra State Board\n",
      "----------------------------------------------------\n",
      "applying_expertise  :  POC POA for new requirementsMigrating OnPremises Servers to Microsoft Azurebacking up the VMs onto Azure Backup VaultWorked on multiple pass servicesCreating VM Snapshot cloneWorked on Azure Security Centremaintain the compliance ratiocost management reportsproviding quarterly platform reviewscost optimization recommendationsmanaging monitoring and maintaining the cloud infrastructureensure ticket SLAs are always met and adhered topresenting daily ticketingMOM reportsreplication ASR for different serversmigration and assessment of different Servers DatabasesTroubleshooting Azure technical issuesMigration from Exchange to Office 365distributiongroup creationlicense management\n",
      "----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for key in output.keys():\n",
    "    print(key, ' : ', output[key])\n",
    "    print(\"----------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
