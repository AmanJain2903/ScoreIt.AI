{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2e23e66",
   "metadata": {},
   "source": [
    "# MODEL INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "dee1e416",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datasets\n",
    "import transformers\n",
    "import evaluate\n",
    "import tensorflow as tf\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5020977",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "67fb0799",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClasses(labelEncoder):\n",
    "    classes = set()\n",
    "    classes.add('O')\n",
    "    for label in labelEncoder.keys():\n",
    "        if label == 'O':\n",
    "            continue\n",
    "        l = label[2:]\n",
    "        classes.add(l)\n",
    "    classes = list(classes)\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e5a5d1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResults(predictions, labelEncoderDecoder, tokenizer, inputText):\n",
    "    labelEncoder = labelEncoderDecoder['labelEncoder']\n",
    "    labelDecoder = labelEncoderDecoder['labelDecoder']\n",
    "    labelDecoder = {int(k): v for k, v in labelDecoder.items()}\n",
    "    classes = getClasses(labelEncoder)\n",
    "    results = {}\n",
    "    for label in classes:\n",
    "        results[label] = \"\"\n",
    "    currIndex = 0\n",
    "    while currIndex < len(predictions):\n",
    "        pred = labelDecoder[predictions[currIndex]]\n",
    "        if pred == 'O':\n",
    "            results['O'] += tokenizer.decode(inputText['input_ids'][0][currIndex])\n",
    "        else:\n",
    "            pred = pred[2:]\n",
    "            results[pred] += tokenizer.decode(inputText['input_ids'][0][currIndex])\n",
    "            \n",
    "        currIndex += 1\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6c02d9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tokens_from_resume(text):\n",
    "    # Remove non-breaking spaces and normalize\n",
    "    text = text.replace(\"\\xa0\", \" \").strip()\n",
    "\n",
    "    # Split on words, numbers, and punctuation\n",
    "    tokens = re.findall(r'\\w+|[^\\w\\s]', text, re.UNICODE)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4961f2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(text, modelID, modelPath, labelEncoderDecoder):\n",
    "    tokenizer = transformers.RobertaTokenizerFast.from_pretrained(modelID, add_prefix_space=True)\n",
    "    model = transformers.TFAutoModelForTokenClassification.from_pretrained(modelPath)\n",
    "\n",
    "    if not isinstance(text, list):\n",
    "        text = extract_tokens_from_resume(text)\n",
    "    inputText = tokenizer(text, is_split_into_words=True, truncation=True, padding='max_length', max_length=512, return_tensors='tf')\n",
    "\n",
    "    predictions = model(**inputText).logits\n",
    "    predictions = tf.argmax(predictions, axis=2).numpy()\n",
    "    predictions = np.squeeze(predictions)\n",
    "\n",
    "    results = getResults(predictions, labelEncoderDecoder, tokenizer, inputText)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "de3dcb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_resume_ner_output(raw_output):\n",
    "    processed = {}\n",
    "    multi_value_fields = {\n",
    "        'designation', 'company_name', 'technical_skills',\n",
    "        'soft-skills', 'work_year', 'achievement', 'certification',\n",
    "        'work_cities', 'languages_known'\n",
    "    }\n",
    "    for label, value in raw_output.items():\n",
    "        if not value or value.strip() == \"\":\n",
    "            continue\n",
    "\n",
    "        # Remove any stray special tokens or junk characters\n",
    "        cleaned = value.replace(\"<s>\", \"\").replace(\"</s>\", \"\").replace(\"<pad>\", \"\").strip()\n",
    "\n",
    "        # Remove excessive whitespace and punctuation artifacts\n",
    "        cleaned = \" \".join(cleaned.split())\n",
    "        cleaned = cleaned.replace(\" .\", \".\").replace(\" ,\", \",\").replace(\" :\", \":\").replace(\" %\", \"%\")\n",
    "\n",
    "        # Remove duplicate adjacent words\n",
    "        cleaned = re.sub(r'\\b(\\w+)( \\1\\b)+', r'\\1', cleaned)\n",
    "\n",
    "        # Remove excess punctuation and fix spacing\n",
    "        cleaned = re.sub(r'\\s+', ' ', cleaned)\n",
    "        cleaned = re.sub(r'[\\-\\–\\—]{2,}', '-', cleaned)\n",
    "        cleaned = re.sub(r'([,:;])\\1+', r'\\1', cleaned)\n",
    "\n",
    "        processed[label] = cleaned\n",
    "\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a69a6b",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "dc89ef0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelID = 'roberta-base'\n",
    "modelPath = 'Models/ResumeNERModel-RoBERTaBase'\n",
    "labelEncoderDecoderPath = 'Dataset/LabelEncoderDecoder.json'\n",
    "labelEncoderDecoder = json.load(open(labelEncoderDecoderPath, 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "408d2b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "testInputs = [\"\"\"\n",
    "John Doe  \n",
    "1234 Innovation Way  \n",
    "San Jose, CA 95129  \n",
    "Email: john.doe@example.com  \n",
    "Phone: +1-408-555-1234  \n",
    "LinkedIn: linkedin.com/in/johndoe  \n",
    "GitHub: github.com/johndoe\n",
    "\n",
    "---\n",
    "\n",
    "Objective  \n",
    "To obtain a challenging position as a Software Engineer where I can contribute to innovative projects using my skills in full-stack development, AI, and cloud technologies.\n",
    "\n",
    "---\n",
    "\n",
    "Education  \n",
    "Master of Science in Computer Science  \n",
    "Santa Clara University — Expected Graduation: June 2025  \n",
    "GPA: 3.85 / 4.0\n",
    "\n",
    "Bachelor of Technology in Computer Engineering  \n",
    "Vellore Institute of Technology — Graduated: June 2022  \n",
    "GPA: 8.7 / 10\n",
    "\n",
    "---\n",
    "\n",
    "Experience  \n",
    "\n",
    "Software Engineering Intern — Google LLC, Mountain View, CA  \n",
    "May 2024 – August 2024  \n",
    "- Worked on the Google Photos team to improve backend scalability using Go and Kubernetes  \n",
    "- Reduced latency of image tagging services by 18% through API optimization  \n",
    "- Collaborated with cross-functional teams using Agile and SCRUM practices\n",
    "\n",
    "Data Scientist — Infosys Ltd, Bangalore, India  \n",
    "July 2022 – March 2023  \n",
    "- Built machine learning pipelines for financial fraud detection (95% precision)  \n",
    "- Worked on NLP models using Hugging Face transformers for document classification  \n",
    "- Deployed models using AWS SageMaker and monitored performance in production\n",
    "\n",
    "---\n",
    "\n",
    "Technical Skills  \n",
    "Languages: Python, Java, JavaScript, Go, SQL  \n",
    "Frameworks: TensorFlow, PyTorch, React.js, Flask  \n",
    "Tools: Git, Docker, Kubernetes, AWS, GCP  \n",
    "Databases: PostgreSQL, MongoDB  \n",
    "Soft Skills: Team Leadership, Public Speaking, Project Management\n",
    "\n",
    "---\n",
    "\n",
    "Projects  \n",
    "\n",
    "AI Resume Parser  \n",
    "- Built a smart resume parsing tool using Named Entity Recognition with spaCy  \n",
    "- Achieved 92% accuracy in extracting job titles, skills, and education entities  \n",
    "- Deployed as a web app using Flask and hosted on Heroku\n",
    "\n",
    "Movie Recommender System  \n",
    "- Created a collaborative filtering-based recommender system using Python  \n",
    "- Integrated with TMDb API and deployed using Streamlit\n",
    "\n",
    "---\n",
    "\n",
    "Certifications  \n",
    "- AWS Certified Solutions Architect – Associate  \n",
    "- TensorFlow Developer Certificate\n",
    "\n",
    "---\n",
    "\n",
    "Achievements  \n",
    "- Top 2% in Amazon ML Hackathon 2023  \n",
    "- First place in VIT’s AI DevJam Hackathon 2021  \n",
    "\n",
    "---\n",
    "\n",
    "Languages  \n",
    "English – Fluent  \n",
    "Hindi – Native  \n",
    "Spanish – Intermediate\n",
    "\n",
    "---\n",
    "\n",
    "Interests  \n",
    "AI Art, Hiking, Indie Game Development, Aviation Photography\n",
    "\n",
    "---\n",
    "\n",
    "References  \n",
    "Available upon request\n",
    "\"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4e3416c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = testInputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "5a509720",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at Models/ResumeNERModel-RoBERTaBase were not used when initializing TFRobertaForTokenClassification: ['dropout_75']\n",
      "- This IS expected if you are initializing TFRobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaForTokenClassification were initialized from the model checkpoint at Models/ResumeNERModel-RoBERTaBase.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForTokenClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "result = infer(testData, modelID, modelPath, labelEncoderDecoder)\n",
    "result = postprocess_resume_ner_output(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1632999f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O: John Doe 1234 Innovation Way Jose, CA 95129 Email: john. doe @ example. com Phone: + 1 - 408 - 555 - 1234 LinkedIn: linkedin. com / in / johndoe GitHub: github. com / johndoe - - - Objective To obtain a challenging position as a Software Engineer where I can contribute to innovative projects using my skills in, and. - - - Education — Expected Graduation: 2025 GPA: 3. 85 / 4. 0 — Graduated: June 2022 GPA: 8. 7 / 10 - - - Experience —, View, CA -ed on the Google to - through - using —, - for ( ) -ed for - using and - - - Technical Skills Languages:, SQL Frameworks: Tools, Soft Skills:, - - - Projects - using withCy - A in job titles, skills, and education entities - Deployed as a web app using Flask and - using - and - - - Certifications - - - - - Achievements - - - - - Languages – – – - - - Interests, - - - References Available upon request\n",
      "----------------------------------------\n",
      "place_higher_education: Santa Clara University\n",
      "----------------------------------------\n",
      "analyzing: monitored performance in productionchieved 92% accuracy extracting\n",
      "----------------------------------------\n",
      "certification: AWS Certified Solutions Architect – Associate TensorFlow Developer Certificate\n",
      "----------------------------------------\n",
      "designation: Software Engineering Intern Data Scientist\n",
      "----------------------------------------\n",
      "candidate_city: San\n",
      "----------------------------------------\n",
      "work_year: May 2024 – August 2024 July 2022 – March 2023\n",
      "----------------------------------------\n",
      "achievement: Top 2% in Amazon ML Hackathon 2023 First place in VIT �� s AI DevJam Hackathon 2021\n",
      "----------------------------------------\n",
      "work_with_people: Work team Collaborated with cross - functional teams\n",
      "----------------------------------------\n",
      "company_name: Google LLC Infosys Ltd\n",
      "----------------------------------------\n",
      "applying_expertise: Photos improve backend scalability using Reduced latency of image tagging services by 18% Built machine learning pipelines financial fraud detection% precision Work on NLP models using document classification Deployed models AWS SageMaker AI Resume Parser Built hosted Created Python Integrated with TMDb API deployed using Streamlit\n",
      "----------------------------------------\n",
      "innovative: a smart resume parsing tool Named Entity Recognition on Heroku Movie Recommender System a collaborative filtering - based recommender system\n",
      "----------------------------------------\n",
      "basic_education: June Bachelor of Technology in Computer Engineering\n",
      "----------------------------------------\n",
      "technical_skills: full - stack development AI cloud technologies Go and Kubernetes API optimization Agile and SCRUM practices 95 Hugging Face transformers Python, Java, JavaScript, Go TensorFlow, PyTorch, React. js, Flask: Git, Docker, Kubernetes, AWS GCP Databases: PostgreSQL, MongoDB spa AI Art, Hiking, Indie Game Development Aviation Photography\n",
      "----------------------------------------\n",
      "place_basic_education: Vellore Institute of Technology\n",
      "----------------------------------------\n",
      "work_cities: Mountain Bangalore India\n",
      "----------------------------------------\n",
      "higher_education: Master of Science in Computer Science\n",
      "----------------------------------------\n",
      "soft-skills: Team Leadership Public Speaking Project Management\n",
      "----------------------------------------\n",
      "languages_known: English Fluent Hindi Native Spanish Intermediate\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for key, value in result.items():\n",
    "    if value == '':\n",
    "        continue\n",
    "    print(f\"{key}: {value}\")\n",
    "    print('----------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "6a527209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'text', 'annotations', 'input', 'NER_LABELS', 'NER_TAGS'],\n",
       "    num_rows: 224\n",
       "})"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasetPath = 'Dataset/ResumeDataset.json'\n",
    "dataset = json.load(open(datasetPath, 'r'))\n",
    "dataset = datasets.Dataset.from_dict(dataset)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "09f49b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelID = 'roberta-base'\n",
    "tokenizer = transformers.RobertaTokenizerFast.from_pretrained(modelID, add_prefix_space=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8dd047f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignLabelsWithTokens(labels, word_ids):\n",
    "    newLabels = []\n",
    "    currentWord = None\n",
    "    for wordID in word_ids:\n",
    "        if wordID is None:\n",
    "            newLabels.append(-100)\n",
    "        elif wordID != currentWord: # New Word\n",
    "            currentWord = wordID\n",
    "            newLabels.append(labels[wordID])\n",
    "        else: # Same Word\n",
    "            label = labels[wordID]\n",
    "            newLabels.append(label)\n",
    "    return newLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "2a3c0e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizerFunction(dataset):\n",
    "    tokenized = tokenizer(dataset['input'], truncation=True, is_split_into_words=True, max_length=512, padding='max_length')\n",
    "    tokenized['labels'] =  alignLabelsWithTokens(dataset['NER_TAGS'], tokenized.word_ids())\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "32545e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0d00e4e8bf04ddc8b829bd4083b5909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/224 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 224\n",
       "})"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizedDataset = dataset.map(tokenizerFunction, remove_columns=['input', 'NER_TAGS',  'NER_LABELS',  'text', 'annotations'])\n",
    "tokenizedDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "538e89c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataCollator = transformers.DataCollatorForTokenClassification(tokenizer=tokenizer, return_tensors='tf')\n",
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "938790c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfDataset = tokenizedDataset.to_tf_dataset(\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=dataCollator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "782a3221",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset = tfDataset.take(int(len(tfDataset) * 0.9))\n",
    "remDataset = tfDataset.skip(int(len(tfDataset) * 0.9))\n",
    "valDataset = remDataset.take(int(len(remDataset) * 0.5))\n",
    "testDataset = remDataset.skip(int(len(remDataset) * 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "914042e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testInputs = []\n",
    "for batch in testDataset:\n",
    "    for id in batch['id']:\n",
    "        id = id.numpy()\n",
    "        index = dataset['id'].index(id)\n",
    "        inputText = dataset['text'][index]\n",
    "        testInputs.append(inputText)\n",
    "len(testInputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "0b3dca76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at Models/ResumeNERModel-RoBERTaBase were not used when initializing TFRobertaForTokenClassification: ['dropout_75']\n",
      "- This IS expected if you are initializing TFRobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaForTokenClassification were initialized from the model checkpoint at Models/ResumeNERModel-RoBERTaBase.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForTokenClassification for predictions without further training.\n",
      "Some layers from the model checkpoint at Models/ResumeNERModel-RoBERTaBase were not used when initializing TFRobertaForTokenClassification: ['dropout_75']\n",
      "- This IS expected if you are initializing TFRobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaForTokenClassification were initialized from the model checkpoint at Models/ResumeNERModel-RoBERTaBase.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForTokenClassification for predictions without further training.\n",
      "Some layers from the model checkpoint at Models/ResumeNERModel-RoBERTaBase were not used when initializing TFRobertaForTokenClassification: ['dropout_75']\n",
      "- This IS expected if you are initializing TFRobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaForTokenClassification were initialized from the model checkpoint at Models/ResumeNERModel-RoBERTaBase.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForTokenClassification for predictions without further training.\n",
      "Some layers from the model checkpoint at Models/ResumeNERModel-RoBERTaBase were not used when initializing TFRobertaForTokenClassification: ['dropout_75']\n",
      "- This IS expected if you are initializing TFRobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaForTokenClassification were initialized from the model checkpoint at Models/ResumeNERModel-RoBERTaBase.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForTokenClassification for predictions without further training.\n",
      "Some layers from the model checkpoint at Models/ResumeNERModel-RoBERTaBase were not used when initializing TFRobertaForTokenClassification: ['dropout_75']\n",
      "- This IS expected if you are initializing TFRobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaForTokenClassification were initialized from the model checkpoint at Models/ResumeNERModel-RoBERTaBase.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForTokenClassification for predictions without further training.\n",
      "Some layers from the model checkpoint at Models/ResumeNERModel-RoBERTaBase were not used when initializing TFRobertaForTokenClassification: ['dropout_75']\n",
      "- This IS expected if you are initializing TFRobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaForTokenClassification were initialized from the model checkpoint at Models/ResumeNERModel-RoBERTaBase.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForTokenClassification for predictions without further training.\n",
      "Some layers from the model checkpoint at Models/ResumeNERModel-RoBERTaBase were not used when initializing TFRobertaForTokenClassification: ['dropout_75']\n",
      "- This IS expected if you are initializing TFRobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaForTokenClassification were initialized from the model checkpoint at Models/ResumeNERModel-RoBERTaBase.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForTokenClassification for predictions without further training.\n",
      "Some layers from the model checkpoint at Models/ResumeNERModel-RoBERTaBase were not used when initializing TFRobertaForTokenClassification: ['dropout_75']\n",
      "- This IS expected if you are initializing TFRobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaForTokenClassification were initialized from the model checkpoint at Models/ResumeNERModel-RoBERTaBase.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForTokenClassification for predictions without further training.\n",
      "Some layers from the model checkpoint at Models/ResumeNERModel-RoBERTaBase were not used when initializing TFRobertaForTokenClassification: ['dropout_75']\n",
      "- This IS expected if you are initializing TFRobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaForTokenClassification were initialized from the model checkpoint at Models/ResumeNERModel-RoBERTaBase.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForTokenClassification for predictions without further training.\n",
      "Some layers from the model checkpoint at Models/ResumeNERModel-RoBERTaBase were not used when initializing TFRobertaForTokenClassification: ['dropout_75']\n",
      "- This IS expected if you are initializing TFRobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaForTokenClassification were initialized from the model checkpoint at Models/ResumeNERModel-RoBERTaBase.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForTokenClassification for predictions without further training.\n",
      "Some layers from the model checkpoint at Models/ResumeNERModel-RoBERTaBase were not used when initializing TFRobertaForTokenClassification: ['dropout_75']\n",
      "- This IS expected if you are initializing TFRobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaForTokenClassification were initialized from the model checkpoint at Models/ResumeNERModel-RoBERTaBase.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForTokenClassification for predictions without further training.\n",
      "Some layers from the model checkpoint at Models/ResumeNERModel-RoBERTaBase were not used when initializing TFRobertaForTokenClassification: ['dropout_75']\n",
      "- This IS expected if you are initializing TFRobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaForTokenClassification were initialized from the model checkpoint at Models/ResumeNERModel-RoBERTaBase.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForTokenClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(len(testInputs)):\n",
    "    testData = testInputs[i]\n",
    "    result = infer(testData, modelID, modelPath, labelEncoderDecoder)\n",
    "    result = postprocess_resume_ner_output(result)\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "8ac885e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume ID: 1\n",
      "O: Aniket Kumar Email me on Indeed httpwwwindeedcomrAniketKumar5bf7984ffc21f23c Willing to relocate Anywhere Work Experience Software Developer Oracle Bengaluru Karnataka December 2016 to Present I had been now working at oracle as a software developer and my experience here was quite good enough to be a exampler I had worked here from December 2016 to 2019 from 2019 i had left this job due to my personal reasons Education July 2012 to August 2016 Bachelors Skills IT Skills Languages\n",
      "----------------------------------------\n",
      "designation: Software Engineer\n",
      "----------------------------------------\n",
      "candidate_city: Patna Bihar\n",
      "----------------------------------------\n",
      "work_year: September 2020 to Present\n",
      "----------------------------------------\n",
      "researching: reaserch in mathematics and greater mathematician than rkm\n",
      "----------------------------------------\n",
      "company_name: Microsoft\n",
      "----------------------------------------\n",
      "basic_education: Bachelors in Computer Science\n",
      "----------------------------------------\n",
      "technical_skills: NET C HTML5 Java JavaScript PHP Python SQL Physics mathematics guru Tally pythonDBMS\n",
      "----------------------------------------\n",
      "place_basic_education: IIT Bombay Mumbai Maharashtra\n",
      "----------------------------------------\n",
      "work_cities: Bengaluru Karnataka\n",
      "----------------------------------------\n",
      "languages_known: German Expert\n",
      "----------------------------------------\n",
      "Resume ID: 2\n",
      "O: SUJAY KARMALKAR Email me on Indeed httpwwwindeedcomrSUJAYKARMALKARe00f12079f5ece5d Work Experience Having 3years of experience in Software testing with expertise in Investment Banking Capital Market Designing and executing test cases to ensure that business requirements and functional specifications are tested and fulfilled Expertise in bug tracking process using bug tracking tool Education July 2016 to March 2019 Skills IT Skills\n",
      "----------------------------------------\n",
      "place_higher_education: Punyashlok ahilyadevi holkar University Solapur Maharashtra\n",
      "----------------------------------------\n",
      "designation: Software Test Engineer\n",
      "----------------------------------------\n",
      "adaption_to_change: Willing to relocate Anywhere\n",
      "----------------------------------------\n",
      "candidate_city: Pune Maharashtra\n",
      "----------------------------------------\n",
      "work_year: June 2019 to August 2022\n",
      "----------------------------------------\n",
      "company_name: Tata Consultancy Services TCS\n",
      "----------------------------------------\n",
      "technical_skills: JIRA Agile Jira SDLC SQL Software testing Functional testing Non functional testing Regression testing Retesting Smoke testing Sanity testing\n",
      "----------------------------------------\n",
      "work_cities: Pune Maharashtra\n",
      "----------------------------------------\n",
      "higher_education: Bachelors in Mathematics\n",
      "----------------------------------------\n",
      "Resume ID: 3\n",
      "O: Having of experience as a SQL Server DBA Security creating logins and assigning roles and user mapping Backup and Restoring Databases with troubleshooting DB mail Configuration and Job creation for daily and weekly activities like o ReorganizingRebuilding Indexes o DB Integrity Checkup etc Installation of SQL Server with std practice Configuration of DR plans LogShipping Mirroring Replication and Always ON Handled Performance Tuning issues o Blocking o Dead locking o Indexes o Fragmentation o Statistics Update Handled CPU Memory Disk IO related issues Upgrade and Migration of SQL Server Knowledge of SQL statements and Joins in SQL Basic knowledge of SSIS Willing to Work Experience SQL Server Administrator DBA Redwing Infotech March 2019 to Present Job Profile Installation of SQL Server 2012 2014 2016 2017 and 2019 on remote systems like Backups Restores Database health checkup Reorganizing and Rebuilding Indexes Regularly monitoring of servers which includes Backup Job Monitoring and troubleshoot all the issues on regular basis Assigning roles as per clients requirement and maintaining the user mapping Configuring DB mail as per the requirement Scheduling and maintaining routine Jobs Alerts and Maintenance Plans Handling Blocking and Deadlock issues and troubleshooting accordingly Configuring and monitoring Log Shipping Mirroring Replication Always ON as per clients requirement Keeping the track of databases server related information in Excel sheet Monitoring SQL Server Logs and Windows Event viewer for Troubleshooting the Issue Troubleshooting database and Disk space management issues to maintain the SQL Server to provide maximum availability and high performance Documentation of important information and Education Skills IT Always ON Log Shipping Mirroring Performance Tuning Migration Backup and Recovery Installation Upgrade Maintaining Databases SSIS Indexes\n",
      "----------------------------------------\n",
      "designation: Database\n",
      "----------------------------------------\n",
      "adaption_to_change: relocate Anywhere\n",
      "----------------------------------------\n",
      "candidate_city: Maharashtra\n",
      "----------------------------------------\n",
      "planning: Creating Maintenance plans\n",
      "----------------------------------------\n",
      "work_year: 3 years\n",
      "----------------------------------------\n",
      "work_with_people: sharing it among team members\n",
      "----------------------------------------\n",
      "applying_expertise: Performing Database maintenance activities\n",
      "----------------------------------------\n",
      "basic_education: BE Maharashtra State Board\n",
      "----------------------------------------\n",
      "technical_skills: Skills SQL DBA Replication\n",
      "----------------------------------------\n",
      "work_cities: Pune\n",
      "----------------------------------------\n",
      "Resume ID: 4\n",
      "O: Rajath Rao GH with Reputation for Email me on Indeed httpwwwindeedcomrRajathRaoGH73944de8f5dfcb95 with 4 years of experience drive traffic and boost audience engagement with dynamic marketing and campaigns Salesforce Marketing Cloud Developer with 12 years of evaluating company processes Personal Details Date of Birth Eligible to work in India Highest Career Level 5 years experience Total years of experience 4 Work Experience SALESFORCE Worked closely on configuration and development of emails content block and template activities Developed and executed email marketing campaigns and AB testing on email templates to improve engagements Designed and configured journeys using activities within in exact target tool Worked on for performing file transfer activities such as imports extracts and SQL query Activities Good working experience in Used to build customized solutions and create various email campaigns Enabling dynamic content management and personalization using AmpScript Handson experience in Lists and Data Extension Sender profile setup Content builder Automation studio Journey builder SQL query and all subscriber lists Optimized Web site architecture page construction and site exposure by Improved searchrelated activities through ongoing analysis experimentation and optimization tests using AB testing and multivariate methods with a monthly budget Improved keyword rankings backlinks and increased organic traffic including keyword research Increased brand awareness through the creation and management of social media channels boosting social media engagement by 70\n",
      "----------------------------------------\n",
      "entrepreneurial_thinking: creating journeys based on business needs and creating email templates using Email studio\n",
      "----------------------------------------\n",
      "analyzing: analyzing search engine patterns to direct online placement of keywords and other content\n",
      "----------------------------------------\n",
      "certification: Online Marketing Institute Training Certification in Digital Marketing\n",
      "----------------------------------------\n",
      "supervising: Monitor and evaluate web analytics dashboards and reports to develop and recommend content and marketing strategies\n",
      "----------------------------------------\n",
      "designation: Salesforce Marketing Cloud Developer Diligent Digital Marketer Industry Marketing MARKETING CLOUD DEVELOPER DIGITAL MARKETING SPECIALIST DIGITAL MARKETING INTERN\n",
      "----------------------------------------\n",
      "candidate_city: Bengaluru Karnataka\n",
      "----------------------------------------\n",
      "work_year: March 2021 to April 2022 January 2019 to February 2021 August 2018 to December 2018\n",
      "----------------------------------------\n",
      "company_name: INCUBE STUDIO INCUBE STUDIO DIGITAL MARKETING TRAINGING AND INTERNSHIP OMIT 5INE WEB SOLUTIONS PVT LTD\n",
      "----------------------------------------\n",
      "birth_date: 19940522\n",
      "----------------------------------------\n",
      "applying_expertise: developing effective new strategies and campaigns to maximize the reach and impact0 of online campaigns\n",
      "----------------------------------------\n",
      "technical_skills: Journey builder SFMC Automation Studio Data segmentation Data Management Data modeling and Data pulling using SQL queries AmpScript HTML and CSS\n",
      "----------------------------------------\n",
      "commercial_thinking: specializing in building and implementing strategies focused on contentdriven SEO Worked on different campaigns Realtime transactional Marketing and batch promotional campaigns for targeting maximum subscribers and mass email send programs Strategized developed and managed paid digital marketing across AdWords Instagram and Facebook\n",
      "----------------------------------------\n",
      "work_cities: Bengaluru Karnataka Bengaluru Karnataka Bengaluru Karnataka Bengaluru Karn\n",
      "----------------------------------------\n",
      "Resume ID: 5\n",
      "O: GCPAzureAWS Accomplished Architect with of IT professional expertise with of experience on and experienced with migration of on premises to Cloud systems Work ExperienceGCPuru Karnataka and components were BigQueryCloud StorageData FusionCloud Composer Cloud Dataflow HardwareSoftware Network and Security Guided the team on using these tools and helping in deployments Education 2002 Skills IT Skills Ticketing Tools Service Now JIRA GCPRecommenderCompute EngineCloud Data FusionCloud ComposerBigQueryDatastoreCloud Deployment ManagerCloud Build Cloud FunctionsCloud IdentityCloud Load BalancingCloud Asset InventorySecurity Command CenterCloud StorageVirtual Private Cloud VPC 2 years AzureAdvisorVirtual MachinesData FactorySynapse AnalyticsCosmos DBDeployment ManagerDevOpsFunctions Serverless Compute Active DirectoryLoad BalancingSecurity ControlSecurity CenterDefenderBlob StorageVirtual Network 2 years Online Profile httpwwwlinkedincomindevendracsa Certifications and Licenses\n",
      "----------------------------------------\n",
      "certification: Microsoft Certified Azure Solutions Architect Expert Google Cloud Certified Professional Cloud Architect\n",
      "----------------------------------------\n",
      "deciding: Architect Solution decisions on the Cloud Infrastructure\n",
      "----------------------------------------\n",
      "initiating_actions: Delivered\n",
      "----------------------------------------\n",
      "designation: Cloud Solution Architect Cloud Architect\n",
      "----------------------------------------\n",
      "candidate_city: Bengaluru Karnataka\n",
      "----------------------------------------\n",
      "planning: Design and implement availabilityscalability and performance plans for the managed service in Google Cloud Architected\n",
      "----------------------------------------\n",
      "work_year: 13 plus years Five Years September 2021 to Present\n",
      "----------------------------------------\n",
      "applying_expertise: Architect Administration of Public and Private cloud platforms AzureGoogleAWS implemented to migrate analytics reporting workload from onprem to GCP\n",
      "----------------------------------------\n",
      "basic_education: BE in Electrical and Electronics Engineering\n",
      "----------------------------------------\n",
      "technical_skills: Scripting Python Shell Script OS MS windows Linuxunix VMware\n",
      "----------------------------------------\n",
      "place_basic_education: Salem TN\n",
      "----------------------------------------\n",
      "work_cities: Bengal\n",
      "----------------------------------------\n",
      "Resume ID: 6\n",
      "O: with over 6 years of experience complemented by certification from currently associated with Possesses strong Adept in providing technical support for Networking and Server tools like CACTI PRTG IONI MRTG Solar Winds H Monitor Knowledge on technologies such as RIP OSPF IGRP EIGRP BGP VLAN STP Work Experience Tikona Roles and Responsibilities Handling Technical Operation with Enterprise Support VPN OM NOC Installing configuring and supporting network equipment including routers switches DNS and DHCP Handling various networks devices of different OEMs Cisco Raisecom TP Link D Link Mogra Fortinet Palo Alto Configuring and Troubleshooting Cisco Routers and Switches Updating network equipment to the latest firmware releases Implementing IP routing static and dynamic routing Maximising network performance through ongoing monitoring and troubleshooting Hands on Experience on RF Links Ubiquity Power Bridge Nano Bridge M5 Ligowave Cambium and TP link Radios Liaising with project managers backend teams and service desk engineers Responsible to resolving troubletickets raised by clients through phone email or remote access Customer Service Daytoday support and administration of network firewalls in a highly complex fastevolving global network Handling client issues by generating complaint numbers and visiting the clients site Taking technical decisions and resolving them as per Service Legal Agreement SLA and ensuring that the complaint gets closed as per TAT Ensuring that quick solutions were provided to resolve incidents to ensure that they did not affect the financial aspect of the business Monitoring the entire infrastructure of all the equipment like Routers Switches and WANLAN Network and their smooth functions Ensuring that all the job assignments were completed on a daytoday basis without any delay Analyzing the feedback system received from the customers to enhance the quality of technical support further Providing technical support for corporate customers for VPN ILL and MPLS connectivity Leased lines Wireless Broadband ISDN Customers Installation Maintenance O M Engineer MAKSAT Technologies Coimbatore Tamil Nadu July 2015 to February 2016 Experience in daytoday Network activities and troubleshootin Monitored various radio parameters and channel related parameters of each site Checked for blocked calls dropped calls and optimum intracell and neighbour handover\n",
      "----------------------------------------\n",
      "certification: CCNA\n",
      "----------------------------------------\n",
      "designation: RF Network Executive Engineer RF Network Support Engineer\n",
      "----------------------------------------\n",
      "candidate_city: Coimbatore Tamil Nadu\n",
      "----------------------------------------\n",
      "work_year: February 2017 to Present\n",
      "----------------------------------------\n",
      "company_name: Tikona Infinet Pvt Ltd Infinet Private Ltd\n",
      "----------------------------------------\n",
      "technical_skills: skills in handling various brands of switches like CISCO HUAWEI TPLINK MROTEK and RAISCOME and IT Infrastructure management\n",
      "----------------------------------------\n",
      "work_cities: Coimbatore Tamil Nadu\n",
      "----------------------------------------\n",
      "soft-skills: Highly committed multiskilled and resultoriented\n",
      "----------------------------------------\n",
      "Resume ID: 7\n",
      "O: Kalpesh Panchal Azure Certified Cloud Engineer Email me on Indeed httpwwwindeedcomrKalpeshPanchalf0f07bf1829713a1 Experienced Azure Cloud Engineer committed to maintaining cuttingedge technical skills and upto date industry knowledge Work Experience Responsibilities and its endtoend deployment as per requirement like and V and with for Following the best practices in the case of Files Folders Backup and the IaaS VM Backup like and with dedicated hostpool and shared hostpool of VM and golden image for VM creation Migrating OnPremises Servers to Microsoft Azure with Azure Site recovery and onpremises Active directory to Experience with change incident management tools like and reports deliverables and supporting documents to necessary stakeholders for and for of different clients on different IaaS and PaaS components for platform redundancy and visibility and incidents in line with ITIL frameworks to making escalations minimal for and to necessary stakeholders on Azure either from onprem to Azure or from Azure to Azure Used for and MS Support for issue resolution Azure AD Onprem AD support and Administration Worked on different other cloudbased technologies like\n",
      "----------------------------------------\n",
      "initiating_actions: Implemented multiple network components Deployed Azure IaaS virtual machinesMs Cloud services PaaS role instances Building up the strategy Implemented Azure VDI Creating Managing Azure Active Directory Responsible Monitoring and configuring Alerts Managing IT support tickets changes Responsible Deploy Configure Maintain Compute Storage Virtual Network\n",
      "----------------------------------------\n",
      "designation: Azure Cloud Engineer Cloud Infrastructure Engineer\n",
      "----------------------------------------\n",
      "candidate_city: Mumbai Maharashtra\n",
      "----------------------------------------\n",
      "work_year: July 2020 to Present September 2019 to July 2020\n",
      "----------------------------------------\n",
      "work_with_people: Involved in planning preparing and presenting Involved in preparing and presenting cost management engaging with Internal Teams Vendors\n",
      "----------------------------------------\n",
      "company_name: Cloudxchangeio SL\n",
      "----------------------------------------\n",
      "applying_expertise: POC POA for new requirements Migrating OnPremises Servers to Microsoft Azure backing up the VMs onto Azure Backup Vault Worked on multiple pass services VM Snapshot clone Worked on Azure Security Centre maintain the compliance ratio providing quarterly platform reviews cost optimization recommendations managing monitoring and maintaining the cloud infrastructure ensure ticket SLAs are always met and adhered to presenting daily ticketing MOM reports replication ASR for different servers migration and assessment of different Servers Databases Troubleshooting Azure technical issues\n",
      "----------------------------------------\n",
      "technical_skills: LB Application gateway traffic manager Front Door VNETsubnet UDR ExpressRoute Bastions CDN Virtual network gateway Public IP addresses Network security groups Azure Site recovery Storage accounts App Services Web app API Management services Azure Kubernetes services Azure Container Registry Servicenow BMC remedy FreshService Configuring backup and Azure Migrate CloudBerry Zscaler Bar\n",
      "----------------------------------------\n",
      "work_cities: Vashi Navi Mumbai Maharashtra\n",
      "----------------------------------------\n",
      "Resume ID: 8\n",
      "O: Willing to relocate Anywhere Work Experience Responsibility of Brazil America Chile Canada SouthCentral Africa and Hands on experience in and Hands on experience onjobs backups Experienced in and Hands on experience in and to make them up to date Good knowledge of and them Handson experience in Experienced in and in and other activities Experience in and Experienced in and able to Also got for same Hands on Experience in and Experienced in on doing good workactively for and for the 20122014201620172019 Experienced working in and using Conceptual knowledge on and Experienced in used and for database and for our Website and An Online Database where Covid19 This project was for Codeethon activity and was by our team Project Machine Assisted Career Counsellor Major Project Language with It will take details of a student and upon that this software can predict in which field a student can go This project is to make in their career Education 2019\n",
      "----------------------------------------\n",
      "place_higher_education: Madhav Institute of Technology Gwalior Madhya Pradesh\n",
      "----------------------------------------\n",
      "analyzing: Monitoring resolving blockings troubleshooting Daily checking resolving the tickets drive\n",
      "----------------------------------------\n",
      "deciding: on the priority levels\n",
      "----------------------------------------\n",
      "supervising: around 5060 SQL servers\n",
      "----------------------------------------\n",
      "initiating_actions: pro\n",
      "----------------------------------------\n",
      "designation: MSSQL Database Administrator\n",
      "----------------------------------------\n",
      "adaption_to_change: as per requirements other teams depends\n",
      "----------------------------------------\n",
      "candidate_city: Gwalior Madhya Pradesh\n",
      "----------------------------------------\n",
      "planning: Create database users with Logins assigning the permission to the logins Perform and managed daily database maintenance monitoring and performance tuning tasks developed in 1 Month\n",
      "----------------------------------------\n",
      "work_year: June 2019 to Present\n",
      "----------------------------------------\n",
      "achievement: appreciation from manager Recognized for Client Value Creation selected as best idea given\n",
      "----------------------------------------\n",
      "work_with_people: Work Collaboratory with SAP\n",
      "----------------------------------------\n",
      "company_name: Accenture\n",
      "----------------------------------------\n",
      "applying_expertise: restore Installation configurationupgradation Applying SQL SPCU patches on standalone cluster alwayson servers configuring Mirroring between the servers Security patching upgradation Incident Management Change Management Created Alerts on Log space utilization onpremises migration Handled P1 P2 issues Did automation Prod deployments Project Centralized Database for Hospital Participated in Codeethon Platform hosted on AWS Created Pages using Python\n",
      "----------------------------------------\n",
      "innovative: beneficial for students decision\n",
      "----------------------------------------\n",
      "basic_education: BCA in Computer Applications\n",
      "----------------------------------------\n",
      "technical_skills: backups databases Full back up Log backup SQL backup and restore procedure database recovery performance monitoring Indexing Auditing security maintaining Log space utilization DR Test Cutover over Database startupshutdown Failover to nodes altering database Tlog files adding database to AG groups Failover Cluster monitoring Production Allocating system storage planning storage requirements database system SQL Server HA Mirroring SQL Clustered environment Always On feature PowerShell and TSQLHTML Microsoft Azure AWS Cloud Django Framework Postgres SQL worked on database Description Python IDLE36 and 34 Machine Learning Description\n",
      "----------------------------------------\n",
      "place_basic_education: BIM\n",
      "----------------------------------------\n",
      "commercial_thinking: user can get all details of dedicated hospitals for\n",
      "----------------------------------------\n",
      "organizing: Managing shrinking housekeeping handling production issues\n",
      "----------------------------------------\n",
      "higher_education: MCA in Computer Applications\n",
      "----------------------------------------\n",
      "soft-skills: Fast learner grasp new concepts quickly and efficiently\n",
      "----------------------------------------\n",
      "Resume ID: 9\n",
      "O: Narasimha P Email me on Indeed httpwwwindeedcomrNarasimhaP45df97dd00e93c3c Worked on Good knowledge on and Has 35 years of experience in Knowledge in and Has experience with Experience in like Work Experience Education management Stateoftheart 2017 HR Management Software is comprehensive state 2017 2013 to 2016 2010 to 2013 2008 to 2010 2008 Skills IT Skills Databases and Platforms Management Tools Programming Languages\n",
      "----------------------------------------\n",
      "place_higher_education: Technological University Amalapuram Andhra Pradesh\n",
      "----------------------------------------\n",
      "designation: Software Developer\n",
      "----------------------------------------\n",
      "candidate_city: Hyderabad Telangana\n",
      "----------------------------------------\n",
      "work_year: December 2018 to July 2022\n",
      "----------------------------------------\n",
      "company_name: K3R Global Solutions Private Limited\n",
      "----------------------------------------\n",
      "basic_education: BSc in Comp SSC in Education Board of Secondary School\n",
      "----------------------------------------\n",
      "technical_skills: software development using Net Technologies application development maintenance life cycle process ASPNet MVC Visual Studio 2017 Net 45 framework ASPNet SQL Server 2012 Windows Services WCF Services Knowledge in Android Mobile Applications Release HTML JavaScript CSS developing SQL Server objects Stored Procedures Views ASPNet MVC NET Framework 45 ADONET Angularjs and Technologies WCF Service RDBMS Microsoft SQL Server 2008 2012 MySQL Windows Server 2003 2008 2008R2 2012 Windows 7 10 Operating Systems Vista XP IDE Visual Studio 2017 SubversionSVN C 45 NET JavaScript SQL\n",
      "----------------------------------------\n",
      "place_basic_education: Andhra University Vikas Junior College\n",
      "----------------------------------------\n",
      "work_cities: Hyderabad Telangana\n",
      "----------------------------------------\n",
      "higher_education: MCA\n",
      "----------------------------------------\n",
      "Resume ID: 10\n",
      "O: Rajesh Choudhari Email me on Indeed httpwwwindeedcomrRajeshChoudhari78a1f6a369f0be83 Over All 6 years of Industry Experience Out of That 3 years in Technical Supports Maintenance Department and 2 years in Cloud Adept at learning and implementing new technologies very swiftly Utilized to monitor resources such as to set alarms for notification or automated actions and to monitor logs for a better understanding and operation of the system Work Experience Brief summary about my job key responsibilities as follows Project 01 Intercom CRM Application for Retailer Electronic Gadgets CRM Client Web Mind It solution Role L1 This system is to provide the best solutions to the organizations to manage all their data about Distributors Retailers and the Customers In this system by using Distributor and order module the admin can manage their all tasks Such as Add distributor View Distributor List New Order View all Order View Contacts us enquiry It provides the fully customized CRM system Roles Responsibilities I was actively involved in the above mentioned project the responsibilities I had as follows Integrated Amazon Cloud Watch with Amazon EC2 instances for Created AWS S3 buckets performed folder management in each bucket managed cloud trail logs and objects within each bucket Created Highly Available Environments using AutoScaling Load Balancers and SQS Created monitors alarms and notifications for EC2 hosts using Cloud Watch Strong experience with etc Project 02 Deal Store Client Global Hub Technology Role L1 This system is to provide the best solutions to the organizations to manage all their data about customers Dealers Customization facility Using this system Admin can manage their Dealer list Customer List Various packages Advertisement Banner and Slider Area and category contact us enquiry messages Improve rank Management Make Dynamic website and all It provides the fully customized Ecom system Roles Responsibilities I am currently working on the project Configured and maintained the monitoring and alerting of production and corporate serversstorage using Cloud Watch Design the overall Virtual Private Cloud VPC environment including server instance storage instances subnets availability zones etc Lifecycle replication Manage Security Groups for EC2 instancesIGW routes ACLs Configuring Snapshots and backup AMI and restoration of the same\n",
      "----------------------------------------\n",
      "analyzing: monitoring the log files and track metrics\n",
      "----------------------------------------\n",
      "designation: Cloud Engineer Cloud Engineer Cloud Engineer Cloud Engineer\n",
      "----------------------------------------\n",
      "candidate_city: Pune Maharashtra\n",
      "----------------------------------------\n",
      "work_year: December 2020 to Present\n",
      "----------------------------------------\n",
      "company_name: Satyajeet Enterprises Sat\n",
      "----------------------------------------\n",
      "innovative: Created monitors alarms and notifications for EC2 hosts using Cloud Watch S3 bucket admin ACLs policies\n",
      "----------------------------------------\n",
      "technical_skills: Cloud Watch EC2 CPU memory Amazon RDS DB services EBS volumes AWS EC2 S3 VPC Security SQS\n",
      "----------------------------------------\n",
      "soft-skills: Drives excellence in every project to deliver outstanding results\n",
      "----------------------------------------\n",
      "Resume ID: 11\n",
      "O: Sangram Deshpande Email me on Indeed httpwwwindeedcomrSangramDeshpande70858840f7745fe4 Work Experience working on the and use in the finance domain Also handling the development side of the project May 2021 Present Implementationofquantumalgorith m f o r Industry Use Case Research skills Education August 2016 to July 2020 Skills IT Skills Online Profile httpsgithubcomSchrodingersSangru httpswwwlinkedincominsangramdeshpande65550a106\n",
      "----------------------------------------\n",
      "place_higher_education: KITs College of Engineering Kolhapur Maharashtra\n",
      "----------------------------------------\n",
      "designation: Software Developer\n",
      "----------------------------------------\n",
      "adaption_to_change: Willing to relocate Anywhere\n",
      "----------------------------------------\n",
      "candidate_city: Jalna Maharashtra\n",
      "----------------------------------------\n",
      "work_year: May 2021 to Present June 2019 to July 2019\n",
      "----------------------------------------\n",
      "company_name: Qulabs software india pvt ltd Quantum\n",
      "----------------------------------------\n",
      "applying_expertise: A system for scrambling data in Galois field using Quantum Computing approach solving differential equation\n",
      "----------------------------------------\n",
      "technical_skills: Quantum Machine learning algorithms Computing Fintech Product design Development Integration of Classical and Quantum Framework Quantum Software Development Python And Related Libraries C Julia Python C HTML5\n",
      "----------------------------------------\n",
      "work_cities: Hyderabad Telangana\n",
      "----------------------------------------\n",
      "higher_education: BTech in Computer Science Engineering\n",
      "----------------------------------------\n",
      "Resume ID: 12\n",
      "O: Work Experience SE Data Cloud Creating Cloud Migration Assessment to migrate on premises to cloud Working on Database Migrations onpremises to azure cloud Creating Data warehouses on the azure cloud according to the requirements according to the data as per client requirements Working on azure cloud to manage the virtual machines Managing end cloud creation Working on databases like MSSQL MySQL Oracle PostgreSQL Making C utilities for client on board as per their requirements Doing RD on various projects to gather during development Creating Web APIs using ASPNET core to gather from the backend Debugging Bugs in existing softwares web applications Managing Complex Databases Stored Procedures to the existing softwares web applications Checking SQL Scripts to investigate the data is sequenced in the proper manner Deploying Web APIs on the virtual machines WORK EXPEREINCE Working on complex Web APIs made on ASPNET core Performing various operations on Angular using the Web APIs Maintaining existing web applications enhancements Working on complex databases of existing applications Resolving Database Issues in the existing applications Making C utilities for client on board as per their requirements Managing Complex Databases Stored Procedures Developing Databases to further project creations Education in Computer Applications 2019 to 2021 in Computer Applications 2016 to 2019 Skills IT Skills Database Administration Cloud Computing Microsoft Azure C ASPNET Angular ASPNET Core Web APIs Oracle Microsoft SQL Server PostgreSQL Online Profile httpwwwdeveshvagalin httpswwwlinkedincomindeveshvagalb258b81b6\n",
      "----------------------------------------\n",
      "place_higher_education: Vikas College of Engineering Technology Mumbai Maharashtra\n",
      "----------------------------------------\n",
      "analyzing: in depth analysis data\n",
      "----------------------------------------\n",
      "designation: Database Consultant Software Engineer Associate Software Engineer Software Trainee\n",
      "----------------------------------------\n",
      "planning: Reports End to End planning to infrastructure\n",
      "----------------------------------------\n",
      "work_year: August 2022 to Present February 2022 to July 2022 May 2021 to February 2022 February 2021 to May 2021\n",
      "----------------------------------------\n",
      "company_name: Ingenium Marine Solutions Pvt Ltd Ingenium Marine Solutions Pvt Ltd Ingenium Marine Solutions Pvt Ltd\n",
      "----------------------------------------\n",
      "innovative: Adding new functionalities\n",
      "----------------------------------------\n",
      "basic_education: Bachelors in Computer Applications\n",
      "----------------------------------------\n",
      "technical_skills: Power BI Database Development\n",
      "----------------------------------------\n",
      "place_basic_education: Vikas College of Engineering Technology Mumbai Maharashtra\n",
      "----------------------------------------\n",
      "organizing: Creating BI Dashboards\n",
      "----------------------------------------\n",
      "work_cities: Thane Maharashtra\n",
      "----------------------------------------\n",
      "higher_education: Masters in Computer Applications\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(results)):\n",
    "    print(f\"Resume ID: {i+1}\")\n",
    "    for key, value in results[i].items():\n",
    "        if value == '':\n",
    "            continue\n",
    "        print(f\"{key}: {value}\")\n",
    "        print('----------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
